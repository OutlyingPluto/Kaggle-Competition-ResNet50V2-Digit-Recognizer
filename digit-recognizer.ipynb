{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a57d78",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:11.401820Z",
     "iopub.status.busy": "2023-12-21T14:52:11.401526Z",
     "iopub.status.idle": "2023-12-21T14:52:25.684392Z",
     "shell.execute_reply": "2023-12-21T14:52:25.683560Z"
    },
    "papermill": {
     "duration": 14.291161,
     "end_time": "2023-12-21T14:52:25.686590",
     "exception": false,
     "start_time": "2023-12-21T14:52:11.395429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed9ceb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.697794Z",
     "iopub.status.busy": "2023-12-21T14:52:25.696866Z",
     "iopub.status.idle": "2023-12-21T14:52:25.702031Z",
     "shell.execute_reply": "2023-12-21T14:52:25.701203Z"
    },
    "papermill": {
     "duration": 0.012315,
     "end_time": "2023-12-21T14:52:25.703810",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.691495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def import_resnet50v2():\n",
    "    # importing resnet50v2 from keras\n",
    "    model = keras.applications.ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(32,32,3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nResnet50V2 has been imported\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6d6b2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.713819Z",
     "iopub.status.busy": "2023-12-21T14:52:25.713569Z",
     "iopub.status.idle": "2023-12-21T14:52:25.717274Z",
     "shell.execute_reply": "2023-12-21T14:52:25.716472Z"
    },
    "papermill": {
     "duration": 0.011265,
     "end_time": "2023-12-21T14:52:25.719554",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.708289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resnet50v2_pretrained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e6004b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.730098Z",
     "iopub.status.busy": "2023-12-21T14:52:25.729822Z",
     "iopub.status.idle": "2023-12-21T14:52:25.738013Z",
     "shell.execute_reply": "2023-12-21T14:52:25.737226Z"
    },
    "papermill": {
     "duration": 0.015329,
     "end_time": "2023-12-21T14:52:25.739847",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.724518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 15TH BATCH TRAINING AND ONWARDS, LAYERS FROZE TILL: conv5_block2_preact_bn\n",
    "# 12TH till 14th BATCH TRAINING, LAYERS FROZE TILL: conv5_block3_preact_bn\n",
    "# 1ST TILL 11TH BATCH TRAINING, ALL LAYERS FROZE\n",
    "\n",
    "# freezing resnet50v2 layers after conv5_block2\n",
    "\n",
    "def freeze_layers(model, layer='none'):\n",
    "    \n",
    "    if layer == 'none':\n",
    "\n",
    "        # freezing models all layers\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "            \n",
    "        # Assuming your model is named 'model'\n",
    "        trainable_count = np.sum([np.prod(w.shape) for w in model.trainable_weights])\n",
    "            \n",
    "        print(\"All layers froze\")\n",
    "        print(f\"Trainable parameters: {trainable_count}\\n\")\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # Find the index of the layer you want to stop freezing at\n",
    "        stop_layer_name = layer\n",
    "        stop_layer_index = None\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if stop_layer_name in layer.name:\n",
    "                stop_layer_index = i\n",
    "                break\n",
    "\n",
    "        # Freeze layers up to the stop layer\n",
    "        for layer in model.layers[:stop_layer_index + 1]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Unfreeze layers after the stop layer\n",
    "        for layer in model.layers[stop_layer_index + 1:]:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # Assuming your model is named 'model'\n",
    "        trainable_count = np.sum([np.prod(w.shape) for w in model.trainable_weights])\n",
    "\n",
    "        print(f\"All layers froze prior to '{stop_layer_name}'\")\n",
    "        print(f\"Trainable parameters: {trainable_count}\\n\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66e82dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.749831Z",
     "iopub.status.busy": "2023-12-21T14:52:25.749576Z",
     "iopub.status.idle": "2023-12-21T14:52:25.756239Z",
     "shell.execute_reply": "2023-12-21T14:52:25.755419Z"
    },
    "papermill": {
     "duration": 0.013723,
     "end_time": "2023-12-21T14:52:25.758138",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.744415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transofrming data for training\n",
    "\n",
    "def transform_data_for_training(file_path):\n",
    "    \n",
    "    # importing training data\n",
    "    train_data = pd.read_csv(file_path)\n",
    "\n",
    "    # specifying size of the image\n",
    "    img_size_org = (28,28,1)\n",
    "\n",
    "    # separating labels\n",
    "    train_targets = train_data['label']\n",
    "    train_features = train_data.drop('label', axis=1)\n",
    "\n",
    "    # one-hot-encoding targets\n",
    "    train_targets = pd.get_dummies(train_targets, columns=['label'])\n",
    "\n",
    "    # normalizing features\n",
    "    train_features = train_features / 255\n",
    "\n",
    "    # converting pandas dataframe to numpy array\n",
    "    train_targets = train_targets.values\n",
    "    train_features = train_features.values\n",
    "\n",
    "    # resizing orignal images dimension and number of channels to the required dimensions and number of channels\n",
    "    train_features = train_features.reshape((42000,28,28))\n",
    "    train_features = np.expand_dims(train_features, axis=-1)\n",
    "    train_features = tf.image.grayscale_to_rgb(tf.convert_to_tensor(train_features))\n",
    "    train_features = tf.image.resize(train_features, (32,32))\n",
    "    train_features = train_features.numpy()\n",
    "    \n",
    "    return train_features, train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0983adcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.768879Z",
     "iopub.status.busy": "2023-12-21T14:52:25.768627Z",
     "iopub.status.idle": "2023-12-21T14:52:25.773391Z",
     "shell.execute_reply": "2023-12-21T14:52:25.772634Z"
    },
    "papermill": {
     "duration": 0.011748,
     "end_time": "2023-12-21T14:52:25.775314",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.763566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# splitting training data\n",
    "\n",
    "def train_val_split(train_features, train_targets, training_ratio, random_seed):\n",
    "    \n",
    "    # setting a fixed seed for reproducibility\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "    # splitting data between train, dev, and test sets\n",
    "    training_ratio = 0.9\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_features, train_targets, test_size=(1-training_ratio))\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14d8830",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.785478Z",
     "iopub.status.busy": "2023-12-21T14:52:25.784836Z",
     "iopub.status.idle": "2023-12-21T14:52:25.798095Z",
     "shell.execute_reply": "2023-12-21T14:52:25.797274Z"
    },
    "papermill": {
     "duration": 0.020186,
     "end_time": "2023-12-21T14:52:25.799912",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.779726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating resnet50v2 with added layers\n",
    "\n",
    "def resnet50v2_custom_create(resnet50v2_pretrained, model_name, random_seed, learningrate, momentum, dropoutrate, L2_regularizer):\n",
    "        \n",
    "    # building the model\n",
    "    model = Sequential(name=model_name)\n",
    "    \n",
    "    # adding final layers to train\n",
    "    model.add(resnet50v2_pretrained)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropoutrate))\n",
    "    model.add(Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropoutrate))\n",
    "    model.add(Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropoutrate))\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropoutrate))\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropoutrate))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # printing models summary\n",
    "    model.summary()\n",
    "\n",
    "    # setting up learning rate decay\n",
    "    # lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(learningrate, decay_steps=X_train.shape[0]/batchsize, decay_rate=lrdecay, staircase=False)\n",
    "\n",
    "    # compiling model and setting hyperparameters\n",
    "    model.compile(optimizer=Adam(learning_rate=learningrate, beta_1=momentum), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n",
    "    total_params = trainable_count + non_trainable_count\n",
    "    \n",
    "    return model, total_params, trainable_count, non_trainable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6287016b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.809722Z",
     "iopub.status.busy": "2023-12-21T14:52:25.809468Z",
     "iopub.status.idle": "2023-12-21T14:52:25.815651Z",
     "shell.execute_reply": "2023-12-21T14:52:25.814911Z"
    },
    "papermill": {
     "duration": 0.013219,
     "end_time": "2023-12-21T14:52:25.817502",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.804283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training resnet50v2 with added layers\n",
    "\n",
    "def resnet50v2_custom_train(model, X_train, y_train, X_val, y_val, batchsize, epoch):\n",
    "        \n",
    "    checkpoint_path = f\"/kaggle/working/{model.name}.h5\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # training model\n",
    "    history = model.fit(X_train, y_train, epochs=epoch, batch_size=batchsize, validation_data=(X_val, y_val), callbacks=[cp_callback])\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the elapsed time\n",
    "    training_time = end_time - start_time\n",
    "\n",
    "    # Format the time as hours, minutes, and seconds\n",
    "    training_time_formatted = time.strftime(\"%H:%M:%S\", time.gmtime(training_time))\n",
    "        \n",
    "    return history, training_time_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b32d50cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.827768Z",
     "iopub.status.busy": "2023-12-21T14:52:25.827233Z",
     "iopub.status.idle": "2023-12-21T14:52:25.836737Z",
     "shell.execute_reply": "2023-12-21T14:52:25.836007Z"
    },
    "papermill": {
     "duration": 0.016477,
     "end_time": "2023-12-21T14:52:25.838511",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.822034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_graph(history, model_name, training_time_formatted):\n",
    "    \n",
    "    # Plotting/Saving Graphs\n",
    "    # Extract the training history\n",
    "    train_loss = history.history['loss']\n",
    "    train_accuracy = history.history['accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')\n",
    "    plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Training Accuracy')\n",
    "    plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    legend_text = f'Model Name: {model_name}\\nLearning Rate: {learningrate:.5f}\\nMomentum: {momentum:.3f}\\nDropout Rate: {dropoutrate:.3f}\\nBatch Size: {batchsize}\\nEpochs: {epoch}\\nTraining Time: {training_time_formatted}'\n",
    "    plt.figtext(0.01, 0.01, legend_text, fontsize=10, va=\"bottom\", ha=\"left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figures to the specified directory\n",
    "    figure_name = f\"{model_name}_lowest_val_loss_{min(history.history['val_loss']):.4f}_15th_batch_training.png\"  # Replace with your desired file name\n",
    "    save_dir = \"/kaggle/working\"\n",
    "    figure_path = os.path.join(save_dir, figure_name)\n",
    "    plt.savefig(figure_path)\n",
    "    plt.close()  # Close the figure to release resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a738b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:25.848333Z",
     "iopub.status.busy": "2023-12-21T14:52:25.848092Z",
     "iopub.status.idle": "2023-12-21T14:52:34.762746Z",
     "shell.execute_reply": "2023-12-21T14:52:34.761584Z"
    },
    "papermill": {
     "duration": 8.92229,
     "end_time": "2023-12-21T14:52:34.765181",
     "exception": false,
     "start_time": "2023-12-21T14:52:25.842891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  13\n",
      "\n",
      "Hyperparameter Values:\n",
      "Learning Rates:  [0.001, 0.001, 0.001, 0.002, 0.002, 0.002, 0.003, 0.003, 0.003]\n",
      "Momentums:  [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\n",
      "Dropout Rates:  [0.5, 0.6, 0.7, 0.5, 0.6, 0.7, 0.5, 0.6, 0.7]\n",
      "Batch Sizes:  [256, 256, 256, 256, 256, 256, 256, 256, 256]\n",
      "Epochs:  1\n",
      "\n",
      "Data Distribution:\n",
      "training features = (37800, 32, 32, 3)\n",
      "training targets = (37800, 10)\n",
      "validation features = (4200, 32, 32, 3)\n",
      "validation targets = (4200, 10)\n",
      "X_train = 90.00%\n",
      "X_val = 10.00%\n",
      "y_train = 90.00%\n",
      "y_val = 10.00%\n"
     ]
    }
   ],
   "source": [
    "# LAST RAN: 14th Batch\n",
    "\n",
    "# specifying a fixed seed for reproducibility\n",
    "random_seed = 13\n",
    "\n",
    "# file path of training data\n",
    "file_path = \"/kaggle/input/digit-recognizer/train.csv\"\n",
    "\n",
    "# training ratio to split data on\n",
    "training_ratio = 0.9\n",
    "\n",
    "# hyperparameter values\n",
    "learningrates = [0.001, 0.001, 0.001, 0.002, 0.002, 0.002, 0.003, 0.003, 0.003]\n",
    "momentums = [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\n",
    "dropoutrates = [0.5, 0.6, 0.7, 0.5, 0.6, 0.7, 0.5, 0.6, 0.7]\n",
    "L2_regularizers = [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]\n",
    "batchsizes = [256, 256, 256, 256, 256, 256, 256, 256, 256]\n",
    "epoch = 1\n",
    "\n",
    "# transforming raw data for training\n",
    "train_features, train_targets = transform_data_for_training(file_path)\n",
    "        \n",
    "# splitting data into trainning and validation sets\n",
    "X_train, X_val, y_train, y_val = train_val_split(train_features, train_targets, training_ratio, random_seed)\n",
    "\n",
    "# printing hyperparameter values and data distribution\n",
    "print(\"Random Seed: \", random_seed)\n",
    "print(\"\\nHyperparameter Values:\")\n",
    "print(\"Learning Rates: \", learningrates)\n",
    "print(\"Momentums: \", momentums)\n",
    "print(\"Dropout Rates: \", dropoutrates)\n",
    "print(\"Batch Sizes: \", batchsizes)\n",
    "print(\"Epochs: \", epoch)\n",
    "print(\"\\nData Distribution:\")\n",
    "print(f'training features = {X_train.shape}')\n",
    "print(f'training targets = {y_train.shape}')\n",
    "print(f'validation features = {X_val.shape}')\n",
    "print(f'validation targets = {y_val.shape}')\n",
    "# print(f'test features = {X_test.shape}')\n",
    "# print(f'test targets = {y_test.shape}')\n",
    "print(f'X_train = {(X_train.shape[0]/train_features.shape[0])*100:.2f}%')\n",
    "print(f'X_val = {(X_val.shape[0]/train_features.shape[0])*100:.2f}%')\n",
    "# print(f'X_test = {(X_test.shape[0]/train_features.shape[0])*100:.2f}%')\n",
    "print(f'y_train = {(y_train.shape[0]/train_targets.shape[0])*100:.2f}%')\n",
    "print(f'y_val = {(y_val.shape[0]/train_targets.shape[0])*100:.2f}%')\n",
    "# print(f'y_test = {(y_test.shape[0]/train_targets.shape[0])*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4b8c884",
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2023-12-21T14:52:34.778524Z",
     "iopub.status.busy": "2023-12-21T14:52:34.778137Z",
     "iopub.status.idle": "2023-12-21T14:56:30.972200Z",
     "shell.execute_reply": "2023-12-21T14:56:30.971296Z"
    },
    "papermill": {
     "duration": 236.203731,
     "end_time": "2023-12-21T14:56:30.974600",
     "exception": false,
     "start_time": "2023-12-21T14:52:34.770869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94668760/94668760 [==============================] - 1s 0us/step\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper (ModuleWrap  (None, 2048)              0         \n",
      " per)                                                            \n",
      "                                                                 \n",
      " module_wrapper_1 (ModuleWr  (None, 1024)              2098176   \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 1024)              4096      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_2 (ModuleWr  (None, 512)               524800    \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_3 (ModuleWr  (None, 256)               131328    \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_4 (ModuleWr  (None, 128)               32896     \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_5 (ModuleWr  (None, 64)                8256      \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_6 (ModuleWr  (None, 32)                2080      \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_7 (ModuleWr  (None, 10)                330       \n",
      " apper)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "148/148 [==============================] - ETA: 0s - loss: 1.9777 - accuracy: 0.2867\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_1.h5\n",
      "148/148 [==============================] - 31s 67ms/step - loss: 1.9777 - accuracy: 0.2867 - val_loss: 2.0379 - val_accuracy: 0.2545\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper_8 (ModuleWr  (None, 2048)              0         \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " module_wrapper_9 (ModuleWr  (None, 1024)              2098176   \n",
      " apper)                                                          \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 1024)              4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_10 (ModuleW  (None, 512)               524800    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_11 (ModuleW  (None, 256)               131328    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_12 (ModuleW  (None, 128)               32896     \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_13 (ModuleW  (None, 64)                8256      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_14 (ModuleW  (None, 32)                2080      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_15 (ModuleW  (None, 10)                330       \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "147/148 [============================>.] - ETA: 0s - loss: 2.3480 - accuracy: 0.1658\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_2.h5\n",
      "148/148 [==============================] - 17s 49ms/step - loss: 2.3467 - accuracy: 0.1660 - val_loss: 2.1741 - val_accuracy: 0.1269\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper_16 (ModuleW  (None, 2048)              0         \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_17 (ModuleW  (None, 1024)              2098176   \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_18 (ModuleW  (None, 512)               524800    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_19 (ModuleW  (None, 256)               131328    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_20 (ModuleW  (None, 128)               32896     \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_21 (ModuleW  (None, 64)                8256      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_22 (ModuleW  (None, 32)                2080      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_23 (ModuleW  (None, 10)                330       \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "147/148 [============================>.] - ETA: 0s - loss: 2.2945 - accuracy: 0.1715\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_3.h5\n",
      "148/148 [==============================] - 17s 50ms/step - loss: 2.2931 - accuracy: 0.1717 - val_loss: 2.0880 - val_accuracy: 0.1776\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper_24 (ModuleW  (None, 2048)              0         \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_25 (ModuleW  (None, 1024)              2098176   \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_26 (ModuleW  (None, 512)               524800    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_27 (ModuleW  (None, 256)               131328    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_28 (ModuleW  (None, 128)               32896     \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_29 (ModuleW  (None, 64)                8256      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_30 (ModuleW  (None, 32)                2080      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_31 (ModuleW  (None, 10)                330       \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "147/148 [============================>.] - ETA: 0s - loss: 2.0178 - accuracy: 0.2323\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_4.h5\n",
      "148/148 [==============================] - 18s 50ms/step - loss: 2.0166 - accuracy: 0.2324 - val_loss: 2.0355 - val_accuracy: 0.3076\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper_32 (ModuleW  (None, 2048)              0         \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_33 (ModuleW  (None, 1024)              2098176   \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_34 (ModuleW  (None, 512)               524800    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_35 (ModuleW  (None, 256)               131328    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_36 (ModuleW  (None, 128)               32896     \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_37 (ModuleW  (None, 64)                8256      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_38 (ModuleW  (None, 32)                2080      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_39 (ModuleW  (None, 10)                330       \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "147/148 [============================>.] - ETA: 0s - loss: 2.1273 - accuracy: 0.1986\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_5.h5\n",
      "148/148 [==============================] - 17s 50ms/step - loss: 2.1267 - accuracy: 0.1988 - val_loss: 2.0643 - val_accuracy: 0.2286\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper_40 (ModuleW  (None, 2048)              0         \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_41 (ModuleW  (None, 1024)              2098176   \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_42 (ModuleW  (None, 512)               524800    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_43 (ModuleW  (None, 256)               131328    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_44 (ModuleW  (None, 128)               32896     \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_45 (ModuleW  (None, 64)                8256      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_46 (ModuleW  (None, 32)                2080      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_47 (ModuleW  (None, 10)                330       \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "148/148 [==============================] - ETA: 0s - loss: 2.2674 - accuracy: 0.1785\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_6.h5\n",
      "148/148 [==============================] - 18s 50ms/step - loss: 2.2674 - accuracy: 0.1785 - val_loss: 2.1294 - val_accuracy: 0.1983\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper_48 (ModuleW  (None, 2048)              0         \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_49 (ModuleW  (None, 1024)              2098176   \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_50 (ModuleW  (None, 512)               524800    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_51 (ModuleW  (None, 256)               131328    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_52 (ModuleW  (None, 128)               32896     \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_53 (ModuleW  (None, 64)                8256      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_54 (ModuleW  (None, 32)                2080      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_55 (ModuleW  (None, 10)                330       \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "147/148 [============================>.] - ETA: 0s - loss: 1.7863 - accuracy: 0.3155\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_7.h5\n",
      "148/148 [==============================] - 17s 50ms/step - loss: 1.7854 - accuracy: 0.3157 - val_loss: 2.7224 - val_accuracy: 0.2967\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper_56 (ModuleW  (None, 2048)              0         \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_57 (ModuleW  (None, 1024)              2098176   \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_58 (ModuleW  (None, 512)               524800    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_59 (ModuleW  (None, 256)               131328    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_60 (ModuleW  (None, 128)               32896     \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_61 (ModuleW  (None, 64)                8256      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_62 (ModuleW  (None, 32)                2080      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_63 (ModuleW  (None, 10)                330       \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "147/148 [============================>.] - ETA: 0s - loss: 2.1177 - accuracy: 0.1938\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_8.h5\n",
      "148/148 [==============================] - 18s 52ms/step - loss: 2.1174 - accuracy: 0.1938 - val_loss: 2.1946 - val_accuracy: 0.2021\n",
      "\n",
      "Resnet50V2 has been imported\n",
      "All layers froze prior to 'conv5_block2_preact_bn'\n",
      "Trainable parameters: 8929280\n",
      "\n",
      "Model: \"resnet50v2_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " module_wrapper_64 (ModuleW  (None, 2048)              0         \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_65 (ModuleW  (None, 1024)              2098176   \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 1024)              4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " module_wrapper_66 (ModuleW  (None, 512)               524800    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_41 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " module_wrapper_67 (ModuleW  (None, 256)               131328    \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_42 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " module_wrapper_68 (ModuleW  (None, 128)               32896     \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_43 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " module_wrapper_69 (ModuleW  (None, 64)                8256      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " batch_normalization_44 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " module_wrapper_70 (ModuleW  (None, 32)                2080      \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      " module_wrapper_71 (ModuleW  (None, 10)                330       \n",
      " rapper)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26370602 (100.60 MB)\n",
      "Trainable params: 11731114 (44.75 MB)\n",
      "Non-trainable params: 14639488 (55.85 MB)\n",
      "_________________________________________________________________\n",
      "148/148 [==============================] - ETA: 0s - loss: 2.1605 - accuracy: 0.1883\n",
      "Epoch 1: saving model to /kaggle/working/resnet50v2_9.h5\n",
      "148/148 [==============================] - 18s 51ms/step - loss: 2.1605 - accuracy: 0.1883 - val_loss: 2.0733 - val_accuracy: 0.2048\n"
     ]
    }
   ],
   "source": [
    "# run this code cell to train and save models stats\n",
    "\n",
    "modelnames = []\n",
    "totalparameters = []\n",
    "trainableparameters = []\n",
    "nontrainableparameters = []\n",
    "\n",
    "for i in range (0, len(learningrates)):\n",
    "    \n",
    "    modelname = f\"resnet50v2_{i+1}\"\n",
    "    modelnames.append(modelname)\n",
    "    \n",
    "    # hyperparameter values\n",
    "    learningrate = learningrates[i]\n",
    "    momentum = momentums[i]\n",
    "    dropoutrate = dropoutrates[i]\n",
    "    L2_regularizer = L2_regularizers[i]\n",
    "    batchsize = batchsizes[i]\n",
    "    \n",
    "    # importing renset50v2 pretrained \n",
    "    resnet50v2_pretrained = import_resnet50v2()\n",
    "        \n",
    "    # freezing layers of resnet50v2\n",
    "    first_trainable_layer = 'conv5_block2_preact_bn'\n",
    "    resnet50v2_pretrained = freeze_layers(resnet50v2_pretrained, 'conv5_block2_preact_bn')\n",
    "    \n",
    "    # create resnet50v2 with added layers\n",
    "    model, totalparams, trainableparams, nontrainableparams = resnet50v2_custom_create(resnet50v2_pretrained, modelname, random_seed, learningrate, momentum, dropoutrate, L2_regularizer)        \n",
    "    \n",
    "    # appending parameters for record keeping\n",
    "    totalparameters.append(totalparams)\n",
    "    trainableparameters.append(trainableparams)\n",
    "    nontrainableparameters.append(nontrainableparams)\n",
    "    \n",
    "    # train the model\n",
    "    history, training_time_formatted = resnet50v2_custom_train(model, X_train, y_train, X_val, y_val, batchsize, epoch)\n",
    "\n",
    "    # plotting graph\n",
    "    plot_graph(history, model.name, training_time_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3fc7186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:56:31.190100Z",
     "iopub.status.busy": "2023-12-21T14:56:31.189386Z",
     "iopub.status.idle": "2023-12-21T14:56:50.235628Z",
     "shell.execute_reply": "2023-12-21T14:56:50.234594Z"
    },
    "papermill": {
     "duration": 19.152576,
     "end_time": "2023-12-21T14:56:50.237706",
     "exception": false,
     "start_time": "2023-12-21T14:56:31.085130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 2s 14ms/step - loss: 2.0379 - accuracy: 0.2545\n",
      "Evaluation of model_1 on validation data\n",
      "Test loss, Test acc: 2.0379 25.45%\n",
      "\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 2.1741 - accuracy: 0.1269\n",
      "Evaluation of model_2 on validation data\n",
      "Test loss, Test acc: 2.1741 12.69%\n",
      "\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 2.0880 - accuracy: 0.1776\n",
      "Evaluation of model_3 on validation data\n",
      "Test loss, Test acc: 2.0880 17.76%\n",
      "\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 2.0355 - accuracy: 0.3076\n",
      "Evaluation of model_4 on validation data\n",
      "Test loss, Test acc: 2.0355 30.76%\n",
      "\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 2.0643 - accuracy: 0.2286\n",
      "Evaluation of model_5 on validation data\n",
      "Test loss, Test acc: 2.0643 22.86%\n",
      "\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 2.1294 - accuracy: 0.1983\n",
      "Evaluation of model_6 on validation data\n",
      "Test loss, Test acc: 2.1294 19.83%\n",
      "\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 2.7224 - accuracy: 0.2967\n",
      "Evaluation of model_7 on validation data\n",
      "Test loss, Test acc: 2.7224 29.67%\n",
      "\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 2.1946 - accuracy: 0.2021\n",
      "Evaluation of model_8 on validation data\n",
      "Test loss, Test acc: 2.1946 20.21%\n",
      "\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 2.0733 - accuracy: 0.2048\n",
      "Evaluation of model_9 on validation data\n",
      "Test loss, Test acc: 2.0733 20.48%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (0, len(learningrates)):    \n",
    "    \n",
    "    # loads the weights\n",
    "    model.load_weights(f\"/kaggle/working/resnet50v2_{i+1}.h5\")\n",
    "    \n",
    "    result = model.evaluate(X_val, y_val)\n",
    "    print(f\"Evaluation of model_{i+1} on validation data\")\n",
    "    print(f\"Test loss, Test acc: {result[0]:.4f} {result[1]*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2447a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-21T14:56:50.494241Z",
     "iopub.status.busy": "2023-12-21T14:56:50.493868Z",
     "iopub.status.idle": "2023-12-21T14:56:50.864490Z",
     "shell.execute_reply": "2023-12-21T14:56:50.863730Z"
    },
    "papermill": {
     "duration": 0.498894,
     "end_time": "2023-12-21T14:56:50.866625",
     "exception": false,
     "start_time": "2023-12-21T14:56:50.367731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths:\n",
      "Model Names: 9\n",
      "Learning Rates: 9\n",
      "Momentums: 9\n",
      "Dropout Rates: 9\n",
      "Batch Sizes: 9\n",
      "Epochs: 9\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 9\n"
     ]
    }
   ],
   "source": [
    "# Check lengths of lists\n",
    "print(\"Lengths:\")\n",
    "print(\"Model Names:\", len(modelnames))\n",
    "print(\"Learning Rates:\", len(learningrates))\n",
    "print(\"Momentums:\", len(momentums))\n",
    "print(\"Dropout Rates:\", len(dropoutrates))\n",
    "print(\"Batch Sizes:\", len(batchsizes))\n",
    "print(\"Epochs:\", len([epoch] * len(modelnames)))\n",
    "print(\"Total params:\", len([totalparameters] * len(modelnames)))\n",
    "print(\"Trainable params:\", len([trainableparameters] * len(modelnames)))\n",
    "print(\"Non-trainable params:\", len([nontrainableparameters] * len(modelnames)))\n",
    "\n",
    "data_distribution = {\n",
    "    'training features': [X_train.shape] * len(modelnames),\n",
    "    'training targets': [y_train.shape] * len(modelnames),\n",
    "    'validation features': [X_val.shape] * len(modelnames),\n",
    "    'validation targets': [y_val.shape] * len(modelnames),\n",
    "    'X_train': [f'{(X_train.shape[0]/train_features.shape[0])*100:.2f}%'] * len(modelnames),\n",
    "    'X_val': [f'{(X_val.shape[0]/train_features.shape[0])*100:.2f}%'] * len(modelnames),\n",
    "    'y_train': [f'{(y_train.shape[0]/train_targets.shape[0])*100:.2f}%'] * len(modelnames),\n",
    "    'y_val': [f'{(y_val.shape[0]/train_targets.shape[0])*100:.2f}%'] * len(modelnames)\n",
    "}\n",
    "model_params = {\n",
    "    'Total params': totalparameters,\n",
    "    'Trainable params': trainableparameters,\n",
    "    'Non-trainable params': nontrainableparameters\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Model Names': modelnames,\n",
    "    'Random Seed': [random_seed] * len(modelnames),\n",
    "    'Learning Rates': learningrates,\n",
    "    'Momentums': momentums,\n",
    "    'Dropout Rates': dropoutrates,\n",
    "    'Batch Sizes': batchsizes,\n",
    "    'Epochs': [epoch] * len(modelnames),\n",
    "    'First Training Layer': [first_trainable_layer] * len(modelnames),\n",
    "    **model_params,\n",
    "    **data_distribution\n",
    "})\n",
    "\n",
    "# Save to Excel file\n",
    "excel_filename = f'/kaggle/working/training_record.xlsx'\n",
    "df.to_excel(excel_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 286.765642,
   "end_time": "2023-12-21T14:56:54.608661",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-21T14:52:07.843019",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
