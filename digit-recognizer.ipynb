{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":7279743,"sourceType":"datasetVersion","datasetId":4213732},{"sourceId":7279781,"sourceType":"datasetVersion","datasetId":4220852}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.python.keras.layers import Dense, Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom keras import backend as K\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport random\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Functions**","metadata":{}},{"cell_type":"code","source":"def import_resnet50v2():\n    # importing resnet50v2 from keras\n    model = keras.applications.ResNet50V2(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=(32,32,3),\n        pooling='avg'\n    )\n    \n    print(\"\\nResnet50V2 has been imported\")\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resnet50v2_pretrained.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 15TH BATCH TRAINING AND ONWARDS, LAYERS FROZE TILL: conv5_block2_preact_bn\n# 12TH till 14th BATCH TRAINING, LAYERS FROZE TILL: conv5_block3_preact_bn\n# 1ST TILL 11TH BATCH TRAINING, ALL LAYERS FROZE\n\n# freezing resnet50v2 layers after conv5_block2\n\ndef freeze_layers(model, layer='none'):\n    \n    if layer == 'none':\n\n        # freezing models all layers\n        for layer in model.layers:\n            layer.trainable = False\n            \n        # Assuming your model is named 'model'\n        trainable_count = np.sum([np.prod(w.shape) for w in model.trainable_weights])\n            \n        print(\"All layers froze\")\n        print(f\"Trainable parameters: {trainable_count}\\n\")\n    \n    else:\n\n        # Find the index of the layer you want to stop freezing at\n        stop_layer_name = layer\n        stop_layer_index = None\n        for i, layer in enumerate(model.layers):\n            if stop_layer_name in layer.name:\n                stop_layer_index = i\n                break\n\n        # Freeze layers up to the stop layer\n        for layer in model.layers[:stop_layer_index + 1]:\n            layer.trainable = False\n\n        # Unfreeze layers after the stop layer\n        for layer in model.layers[stop_layer_index + 1:]:\n            layer.trainable = True\n\n        # Assuming your model is named 'model'\n        trainable_count = np.sum([np.prod(w.shape) for w in model.trainable_weights])\n\n        print(f\"All layers froze prior to '{stop_layer_name}'\")\n        print(f\"Trainable parameters: {trainable_count}\\n\")\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transofrming data for training\n\ndef transform_data_for_training(file_path):\n    \n    # importing training data\n    train_data = pd.read_csv(file_path)\n\n    # specifying size of the image\n    img_size_org = (28,28,1)\n\n    # separating labels\n    train_targets = train_data['label']\n    train_features = train_data.drop('label', axis=1)\n    \n    # converting data to int type\n    train_targets = train_targets.astype(int)\n    train_features = train_features.astype(int)\n\n    # one-hot-encoding targets\n    train_targets = pd.get_dummies(train_targets, columns=['label'])\n\n    # normalizing features\n    train_features = train_features / 255\n\n    # converting pandas dataframe to numpy array\n    train_targets = train_targets.values\n    train_features = train_features.values\n\n    # resizing orignal images dimension and number of channels to the required dimensions and number of channels\n    train_features = train_features.reshape((train_features.shape[0],28,28))\n    train_features = np.expand_dims(train_features, axis=-1)\n    train_features = tf.image.grayscale_to_rgb(tf.convert_to_tensor(train_features))\n    train_features = tf.image.resize(train_features, (32,32))\n    train_features = train_features.numpy()\n    \n    return train_features, train_targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transofrming data for error analysis\n\ndef transform_data_for_erroranalysis(file_path, training_ratio, random_seed):\n    \n    # importing training data\n    train_data = pd.read_csv(file_path)\n\n    # specifying size of the image\n    img_size_org = (28,28,1)\n\n    # separating labels\n    train_targets = train_data['label']\n    train_features = train_data.drop('label', axis=1)\n\n    # one-hot-encoding targets\n    train_targets = pd.get_dummies(train_targets, columns=['label'])\n\n    # normalizing features\n    train_features = train_features / 255\n\n    # added original index to training features\n    train_features['org_index'] = train_features.index\n\n    # converting pandas dataframe to numpy array\n    train_targets = train_targets.values\n    train_features = train_features.values\n\n    # splitting data into trainning and validation sets\n    X_train, X_val, y_train, y_val = train_val_split(train_features, train_targets, training_ratio, random_seed)\n\n    # Find the indices of True values in each row and concatenate into a flat list\n    y_val_trueindices = np.concatenate([np.where(row)[0] for row in y_val])\n\n    # Convert the NumPy array to a Pandas DataFrame\n    X_val_pd = pd.DataFrame(X_val)\n    y_val_pd = pd.DataFrame(y_val_trueindices)\n\n    # Rename the last column to 'label'\n    y_val_pd = y_val_pd.rename(columns={y_val_pd.columns[-1]: 'label'})\n\n    # Concatenate them along the columns\n    merged_df = pd.concat([X_val_pd, y_val_pd], axis=1)\n\n    # Sort the DataFrame based on the 'label' column in ascending order\n    sorted_merged_df = merged_df.sort_values(by='label')\n\n    # separating necessary columns\n    y_val_pd = sorted_merged_df['label']\n    X_val_pd = sorted_merged_df.drop(['label', 784], axis=1)\n    org_index = sorted_merged_df[784]\n    X_train = np.delete(X_train, -1, 1)\n    \n    # one-hot-encoding labels\n    y_val_pd = pd.get_dummies(y_val_pd, columns=['label'])\n\n    # converting pandas dataframe to numpy array\n    y_val = y_val_pd.values\n    X_val = X_val_pd.values\n    org_index = org_index.values\n\n    # resizing orignal images dimension and number of channels to the required dimensions and number of channels\n    X_val = X_val.reshape((4200,28,28))\n    X_val = np.expand_dims(X_val, axis=-1)\n    X_val = tf.image.grayscale_to_rgb(tf.convert_to_tensor(X_val))\n    X_val = tf.image.resize(X_val, (32,32))\n    X_val = X_val.numpy()\n\n    X_train = X_train.reshape((37800,28,28))\n    X_train = np.expand_dims(X_train, axis=-1)\n    X_train = tf.image.grayscale_to_rgb(tf.convert_to_tensor(X_train))\n    X_train = tf.image.resize(X_train, (32,32))\n    X_train = X_train.numpy()\n\n    return X_train, X_val, y_train, y_val, org_index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting training data\n\ndef train_val_split(train_features, train_targets, training_ratio, random_seed):\n    \n    # setting a fixed seed for reproducibility\n    np.random.seed(random_seed)\n    \n    # splitting data between train, dev, and test sets\n    training_ratio = 0.9\n    X_train, X_val, y_train, y_val = train_test_split(train_features, train_targets, test_size=(1-training_ratio))\n    \n    return X_train, X_val, y_train, y_val","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating resnet50v2 with added layers\n\ndef resnet50v2_custom_create(resnet50v2_pretrained, model_name, random_seed, learningrate, momentum, dropoutrate, L2_regularizer):\n        \n    # building the model\n    model = Sequential(name=model_name)\n    \n    # adding final layers to train\n    model.add(resnet50v2_pretrained)\n    model.add(Flatten())\n    model.add(Dense(1024, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros', kernel_regularizer=tf.keras.regularizers.L2(L2_regularizer)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dropout(dropoutrate))\n    model.add(Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros', kernel_regularizer=tf.keras.regularizers.L2(L2_regularizer)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dropout(dropoutrate))\n    model.add(Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros', kernel_regularizer=tf.keras.regularizers.L2(L2_regularizer)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dropout(dropoutrate))\n    model.add(Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros', kernel_regularizer=tf.keras.regularizers.L2(L2_regularizer)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dropout(dropoutrate))\n    model.add(Dense(64, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros', kernel_regularizer=tf.keras.regularizers.L2(L2_regularizer)))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dropout(dropoutrate))\n    model.add(Dense(32, activation='relu', kernel_initializer=tf.keras.initializers.GlorotNormal(seed=random_seed), use_bias=True, bias_initializer='zeros', kernel_regularizer=tf.keras.regularizers.L2(L2_regularizer)))\n    model.add(Dense(10, activation='softmax'))\n\n    # printing models summary\n    model.summary()\n\n    # setting up learning rate decay\n    # lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(learningrate, decay_steps=X_train.shape[0]/batchsize, decay_rate=lrdecay, staircase=False)\n\n    # compiling model and setting hyperparameters\n    model.compile(optimizer=Adam(learning_rate=learningrate, beta_1=momentum), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n    non_trainable_count = np.sum([K.count_params(w) for w in model.non_trainable_weights])\n    total_params = trainable_count + non_trainable_count\n    \n    return model, total_params, trainable_count, non_trainable_count","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training resnet50v2 with added layers\n\ndef resnet50v2_custom_train(model, X_train, y_train, X_val, y_val, batchsize, epoch, directory_path_output):\n        \n    checkpoint_path = f\"{directory_path_output}{model.name}_21st_batch_training.h5\"\n    checkpoint_dir = os.path.dirname(checkpoint_path)\n\n    # Create a callback that saves the model's weights\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n\n    # Record the start time\n    start_time = time.time()\n\n    # training model\n    history = model.fit(X_train, y_train, epochs=epoch, batch_size=batchsize, validation_data=(X_val, y_val), callbacks=[cp_callback])\n\n    # Record the end time\n    end_time = time.time()\n\n    # Calculate the elapsed time\n    training_time = end_time - start_time\n\n    # Format the time as hours, minutes, and seconds\n    training_time_formatted = time.strftime(\"%H:%M:%S\", time.gmtime(training_time))\n        \n    return history, training_time_formatted","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_graph(history, model_name, training_time_formatted, directory_path_output):\n    \n    # Plotting/Saving Graphs\n    # Extract the training history\n    train_loss = history.history['loss']\n    train_accuracy = history.history['accuracy']\n    val_loss = history.history['val_loss']\n    val_accuracy = history.history['val_accuracy']\n\n    # Plot training and validation loss\n    plt.figure(figsize=(16, 12))\n    plt.subplot(1, 2, 1)\n    plt.plot(range(1, len(train_loss) + 1), train_loss, label='Training Loss')\n    plt.plot(range(1, len(val_loss) + 1), val_loss, label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    # Plot training and validation accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(range(1, len(train_accuracy) + 1), train_accuracy, label='Training Accuracy')\n    plt.plot(range(1, len(val_accuracy) + 1), val_accuracy, label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    legend_text = f'Model Name: {model_name}\\nLearning Rate: {learningrate:.5f}\\nMomentum: {momentum:.3f}\\nDropout Rate: {dropoutrate:.3f}\\nL2 Regularizer: {L2_regularizer:.4f}\\nBatch Size: {batchsize}\\nEpochs: {epoch}\\nTraining Time: {training_time_formatted}'\n    plt.figtext(0.01, 0.01, legend_text, fontsize=10, va=\"bottom\", ha=\"left\")\n\n    plt.tight_layout()\n\n    # Save the figures to the specified directory\n    figure_name = f\"{model_name}_lowest_val_loss_{min(history.history['val_loss']):.4f}_21st_batch_training.png\"  # Replace with your desired file name\n    figure_path = os.path.join(directory_path_output, figure_name)\n    plt.savefig(figure_path)\n    plt.close()  # Close the figure to release resources","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Setting Hyperparameter Values**","metadata":{}},{"cell_type":"code","source":"# LAST RAN: 14th Batch\n\n# specifying a fixed seed for reproducibility\nrandom_seed = 13\n\n# file path of training data and directory path of output data\nfile_path_input = \"/kaggle/input/digit-recognizer/train.csv\"\ndirectory_path_output = \"/kaggle/working/\"\n\n# training ratio to split data on\ntraining_ratio = 0.9\n\n# hyperparameter values\nlearningrates = [0.001, 0.001, 0.001, 0.002, 0.002, 0.002, 0.003, 0.003, 0.003]\nmomentums = [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\ndropoutrates = [0.3, 0.4, 0.5, 0.3, 0.4, 0.5, 0.3, 0.4, 0.5]\nL2_regularizers = [0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001]\nbatchsizes = [256, 256, 256, 256, 256, 256, 256, 256, 256]\nepoch = 100\n\n# transforming training data for training\ntrain_features, train_targets = transform_data_for_training(file_path_input)\n\n#transforming augmented data for training\nX_train_aug_1, y_train_aug_1 = transform_data_for_training(\"/kaggle/input/digit-recognizer-augmented-datasets/augmented_data_resnet50v2_5_17th_batch_training_5029.csv\")\nX_train_aug_2, y_train_aug_2 = transform_data_for_training(\"/kaggle/input/digit-recognizer-augmented-datasets/augmented_data_resnet50v2_5_18th_batch_training.csv\")\nX_train_aug_3, y_train_aug_3 = transform_data_for_training(\"/kaggle/input/digit-recognizer-augmented-datasets/augmented_data_resnet50v2_9_19th_batch_training_2520.csv\")\n\n# splitting data into trainning and validation sets\nX_train_non_aug, X_val, y_train_non_aug, y_val = train_val_split(train_features, train_targets, training_ratio, random_seed)\n\n# adding augmented data to training data\nX_train = np.concatenate((X_train_non_aug, X_train_aug_1, X_train_aug_2, X_train_aug_3), axis=0)\ny_train = np.concatenate((y_train_non_aug, y_train_aug_1, y_train_aug_2, y_train_aug_3), axis=0)\n\n# new changes that are made for each training batch\nnew_changes = \"Added 2500 aditional augmented images to training data\"\n\n# printing hyperparameter values and data distribution\nprint(\"Random Seed: \", random_seed)\nprint(\"\\nHyperparameter Values:\")\nprint(\"Learning Rates: \", learningrates)\nprint(\"Momentums: \", momentums)\nprint(\"Dropout Rates: \", dropoutrates)\nprint(\"L2 Regularizers: \", L2_regularizers)\nprint(\"Batch Sizes: \", batchsizes)\nprint(\"Epochs: \", epoch)\nprint(\"\\nData Distribution:\")\nprint(f\"Total Data: {train_features.shape[0]+X_train_aug_1.shape[0]+X_train_aug_2.shape[0]}\")\nprint(f'training features = {X_train.shape}')\nprint(f'training targets = {y_train.shape}')\nprint(f'validation features = {X_val.shape}')\nprint(f'validation targets = {y_val.shape}')\n# print(f'test features = {X_test.shape}')\n# print(f'test targets = {y_test.shape}')\nprint(f'X_train = {(X_train.shape[0]/(train_features.shape[0]+X_train_aug_1.shape[0]+X_train_aug_2.shape[0]+X_train_aug_3.shape[0]))*100:.2f}%')\nprint(f'X_val = {(X_val.shape[0]/(train_features.shape[0]+X_train_aug_1.shape[0]+X_train_aug_2.shape[0]+X_train_aug_3.shape[0]))*100:.2f}%')\n# print(f'X_test = {(X_test.shape[0]/train_features.shape[0])*100:.2f}%')\nprint(f'y_train = {(y_train.shape[0]/(train_targets.shape[0]+X_train_aug_1.shape[0]+X_train_aug_2.shape[0]+X_train_aug_3.shape[0]))*100:.2f}%')\nprint(f'y_val = {(y_val.shape[0]/(train_targets.shape[0]+X_train_aug_1.shape[0]+X_train_aug_2.shape[0]+X_train_aug_3.shape[0]))*100:.2f}%')\n# print(f'y_test = {(y_test.shape[0]/train_targets.shape[0])*100:.2f}%')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training Model**","metadata":{}},{"cell_type":"code","source":"# run this code cell to train and save models stats\n\nmodelnames = []\ntotalparameters = []\ntrainableparameters = []\nnontrainableparameters = []\n\nfor i in range (0, len(learningrates)):\n    \n    modelname = f\"resnet50v2_{i+1}\"\n    modelnames.append(modelname)\n    \n    # hyperparameter values\n    learningrate = learningrates[i]\n    momentum = momentums[i]\n    dropoutrate = dropoutrates[i]\n    L2_regularizer = L2_regularizers[i]\n    batchsize = batchsizes[i]\n    \n    # importing renset50v2 pretrained \n    resnet50v2_pretrained = import_resnet50v2()\n        \n    # freezing layers of resnet50v2\n    first_trainable_layer = 'conv5_block2_preact_bn'\n    resnet50v2_pretrained = freeze_layers(resnet50v2_pretrained, 'conv5_block2_preact_bn')\n    \n    # create resnet50v2 with added layers\n    model, totalparams, trainableparams, nontrainableparams = resnet50v2_custom_create(resnet50v2_pretrained, modelname, random_seed, learningrate, momentum, dropoutrate, L2_regularizer)        \n    \n    # appending parameters for record keeping\n    totalparameters.append(totalparams)\n    trainableparameters.append(trainableparams)\n    nontrainableparameters.append(nontrainableparams)\n    \n    # train the model\n    history, training_time_formatted = resnet50v2_custom_train(model, X_train, y_train, X_val, y_val, batchsize, epoch, directory_path_output)\n\n    # plotting graph\n    plot_graph(history, model.name, training_time_formatted, directory_path_output)","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Saving Training Stats**","metadata":{}},{"cell_type":"code","source":"# Check lengths of lists\n# print(\"Lengths:\")\n# print(\"Model Names:\", len(modelnames))\n# print(\"Learning Rates:\", len(learningrates))\n# print(\"Momentums:\", len(momentums))\n# print(\"Dropout Rates:\", len(dropoutrates))\n# print(\"Batch Sizes:\", len(batchsizes))\n# print(\"Epochs:\", len([epoch] * len(modelnames)))\n# print(\"Total params:\", len([totalparameters] * len(modelnames)))\n# print(\"Trainable params:\", len([trainableparameters] * len(modelnames)))\n# print(\"Non-trainable params:\", len([nontrainableparameters] * len(modelnames)))\n\ndata_distribution = {\n    'training features': [X_train.shape] * len(modelnames),\n    'training targets': [y_train.shape] * len(modelnames),\n    'validation features': [X_val.shape] * len(modelnames),\n    'validation targets': [y_val.shape] * len(modelnames),\n    'X_train': [f'{(X_train.shape[0]/train_features.shape[0])*100:.2f}%'] * len(modelnames),\n    'X_val': [f'{(X_val.shape[0]/train_features.shape[0])*100:.2f}%'] * len(modelnames),\n    'y_train': [f'{(y_train.shape[0]/train_targets.shape[0])*100:.2f}%'] * len(modelnames),\n    'y_val': [f'{(y_val.shape[0]/train_targets.shape[0])*100:.2f}%'] * len(modelnames)\n}\nmodel_params = {\n    'Total params': totalparameters,\n    'Trainable params': trainableparameters,\n    'Non-trainable params': nontrainableparameters\n}\n\n# Create a DataFrame\ndf = pd.DataFrame({\n    'Model Names': modelnames,\n    'New Changes': [new_changes] * len(modelnames),\n    'Random Seed': [random_seed] * len(modelnames),\n    'Learning Rates': learningrates,\n    'Momentums': momentums,\n    'Dropout Rates': dropoutrates,\n    'L2 Regularizers': L2_regularizers,\n    'Batch Sizes': batchsizes,\n    'Epochs': [epoch] * len(modelnames),\n    'First Training Layer': [first_trainable_layer] * len(modelnames),\n    **model_params,\n    **data_distribution\n})\n\n# Save to Excel file\nexcel_filename = f'{directory_path_output}training_record_19th_batch_training.xlsx'\ndf.to_excel(excel_filename, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Evaluating All Models Performance**","metadata":{}},{"cell_type":"code","source":"for i in range (0, len(learningrates)):    \n    \n    # loads the weights\n    model.load_weights(f\"/kaggle/working/resnet50v2_{i+1}_19th_batch_training.h5\")\n    \n    result = model.evaluate(X_val, y_val)\n    print(f\"Evaluation of model_{i+1} on validation data\")\n    print(f\"Test loss, Test acc: {result[0]:.4f} {result[1]*100:.2f}%\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Saving Predicted File On Test Data**","metadata":{}},{"cell_type":"code","source":"# importing training data\ny_test = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n\n# specifying size of the image\nimg_size_org = (28,28,1)\n\n# normalizing features\ny_test = y_test / 255\n\n# converting pandas dataframe to numpy array\ny_test = y_test.values\n\n# resizing orignal images dimension and number of channels to the required dimensions and number of channels\ny_test = y_test.reshape((28000,28,28))\ny_test = np.expand_dims(y_test, axis=-1)\ny_test = tf.image.grayscale_to_rgb(tf.convert_to_tensor(y_test))\ny_test = tf.image.resize(y_test, (32,32))\ny_test = y_test.numpy()\n    \n# loads the weights\nmodel.load_weights(f\"/kaggle/input/resnet50v2-5/resnet50v2_9_18th_batch_training.h5\")\n    \n# making predictions on all classes | shape (28000, 10)\npredictions = model.predict(y_test)\n    \n# assigning labels based on the predictions\npredicted_labels = np.argmax(predictions, axis=1)\n\n# Create a DataFrame with two columns: 'ImageId' and 'Label'\ndf = pd.DataFrame({'ImageId': range(1, len(predicted_labels) + 1), 'Label': predicted_labels})\n\n# Export the DataFrame to a CSV file\ndf.to_csv('resnet50v2_9_predicted_labels_18th_batch_training.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Error Analysis**","metadata":{"execution":{"iopub.status.busy":"2023-12-24T20:17:27.266178Z","iopub.execute_input":"2023-12-24T20:17:27.266598Z","iopub.status.idle":"2023-12-24T20:17:27.271835Z","shell.execute_reply.started":"2023-12-24T20:17:27.266566Z","shell.execute_reply":"2023-12-24T20:17:27.270434Z"}}},{"cell_type":"code","source":"# specifying a fixed seed for reproducibility\nrandom_seed = 15\n\n# file path of training data and directory path of output data\nfile_path_input = \"/kaggle/input/digit-recognizer/train.csv\"\n\n# training ratio to split data on\ntraining_ratio = 0.9\n\n# splitting data into trainning and validation sets\nX_train, X_val, y_train, y_val, org_indexes = transform_data_for_erroranalysis(file_path_input, training_ratio, random_seed)\n\n# importing renset50v2 pretrained \nresnet50v2_pretrained = import_resnet50v2()\n        \n# freezing layers of resnet50v2\nfirst_trainable_layer = 'conv5_block2_preact_bn'\nresnet50v2_pretrained = freeze_layers(resnet50v2_pretrained, 'conv5_block2_preact_bn')\n    \n# create resnet50v2 with added layers\nmodel, totalparams, trainableparams, nontrainableparams = resnet50v2_custom_create(resnet50v2_pretrained, \"resnet50v2\", 13, 0.001, 0.95, 0.5, 0.0001)\n\n# loads the weights\nmodel.load_weights(\"/kaggle/working/resnet50v2_2_19th_batch_training.h5\")\n\nresult = model.evaluate(X_val, y_val)\nprint(f\"Evaluation of resnet50v2-5 on validation data\")\nprint(f\"Test loss, Test acc: {result[0]:.4f} {result[1]*100:.2f}%\\n\")\n\n# making predictions on all classes | shape (28000, 10)\npredictions_val = model.predict(X_val)\n    \n# assigning labels based on the predictions\npredicted_labels_val = np.argmax(predictions_val, axis=1)\n\nprint(\"Length of predicted labels array\", len(predicted_labels_val))\nprint(\"Length of target labels array\", len(y_val))\n\n# Find the indices of True values in each row and concatenate into a flat list\ntrue_indices = np.concatenate([np.where(row)[0] for row in y_val])\n\n# comparing predictions and ground labels\nmismatched_indexes = []\nfor index, (predicted, actual) in enumerate(zip(predicted_labels_val, true_indices)):\n    if not np.array_equal(predicted, actual):\n        mismatched_indexes.append(index)\nprint(f\"\\nPrecentange of wrong labels: {(len(mismatched_indexes)/len(predictions_val)) * 100:.2f}%\")\nprint(f\"Precentange of correct labels: {100-(len(mismatched_indexes)/len(predictions_val)) * 100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming X_val is your validation set and mismatched_indexes is the array of indexes\n# Also, assuming each image in X_val is a 2D array (grayscale) or a 3D array (RGB)\n\n# Define the number of columns in the plot grid\nnum_columns = 5\n\n# Calculate the number of rows needed based on the number of mismatched indexes\nnum_rows = int(np.ceil(len(mismatched_indexes) / num_columns))\n\n# Set up the plot grid\nfig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 3*num_rows))\n\n# Flatten the axes array if the grid is not 2D\naxes = axes.flatten()\n\n# Loop through the mismatched indexes and plot the corresponding images\nfor i, index in enumerate(mismatched_indexes):\n    image = X_val[index]  # Assuming X_val contains the images\n    axes[i].imshow(image, cmap='gray')  # Change 'gray' to 'viridis' or other colormap for RGB images\n    axes[i].set_title(f\"Index: {index}\\nPredicted: {predicted_labels_val[index]}, Actual: {true_indices[index]}\")\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Saving Error Analysis Stats**","metadata":{}},{"cell_type":"code","source":"# Create a DataFrame with 'Index', 'Actual', and 'Predicted' columns\ndata = {'Index': mismatched_indexes,\n        'Actual': [true_indices[index] for index in mismatched_indexes],\n        'Predicted': [predicted_labels_val[index] for index in mismatched_indexes]}\n\ndf_output = pd.DataFrame(data)\n\n# Save the DataFrame to an Excel file\noutput_file_path = '/kaggle/working/error_analysis_resnet50v2_2_20th_batch_training.xlsx'  # Replace with the desired file path\ndf_output.to_excel(output_file_path, index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Augmentation**","metadata":{}},{"cell_type":"markdown","source":">**Run this code cell to get indexes of all mismatched images**","metadata":{}},{"cell_type":"code","source":"print(mismatched_indexes)\nprint(\"Number of mismatched images:\", len(mismatched_indexes))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**Run this code cell to plot images - org_indexes[index] produces the orginial index of the image in training data**","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\n\n# Extract labels and pixel values\nlabels = train_data[\"label\"]\npixels = train_data.drop(\"label\", axis=1)\n\n# Convert label values to numpy array\nlabels_array = np.array(labels)\n\n# Convert pixel values to numpy array\npixels_array = np.array(pixels)\n\n# Reshape the pixel values to 28x28 images (assuming MNIST dataset)\nimages = pixels_array.reshape(-1, 28, 28)\n\n# Function to plot a specific image by index\ndef plot_image(index):\n    plt.imshow(images[index], cmap='gray')\n    plt.title(f\"Label: {labels[index]}\")\n    plt.axis('off')\n    plt.show()\n\n# Plot a specific image by index (change the index as needed)\nplot_image(int(org_indexes[3986]))\n\nprint(images.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Run this code cell to produce the list of images that will be augmented in the next code cell**","metadata":{}},{"cell_type":"code","source":"# list of indexes of images that are not needed for augmentation\nmismatched_indexes_remove = [255, 314, 659, 667, 908, 955, 973, 1025, 1032, 1036, 1051, 1129, 1160, 1230, 1239, 1300, 1358, 1372, 1408, 1442, 1583, 1619, 1640, 1674, 1688, 1707, 1781, 1851, 1881, 1889, 2017, 3039, 3105, 3214, 3275, 3297, 3821, 3822, 3864, 3874, 3986, 4084]\norg_indexes_mismatched_remove = []\nfor i, index in enumerate (mismatched_indexes_remove):\n        # appending indexes of mismatched images only\n        org_indexes_mismatched_remove.append(int(org_indexes[index]))\n\n# creating a list to store only the indexes of mismatched images\norg_indexes_mismatched = []\nfor i, index in enumerate (mismatched_indexes):\n        # appending indexes of mismatched images only\n        org_indexes_mismatched.append(int(org_indexes[index]))\n\n# creating an array to store only the mismatched images and labels,\n# excpet for the ones that are not needed for data augmentation\nimages_mismatched = []\nlabels_mismatched = []\n\nfor i, index in enumerate (org_indexes_mismatched):\n\n    if index not in org_indexes_mismatched_remove:\n        # x stores the image pixels and reshapes it to (1, 28, 28, 1)\n        x = images[index]\n        x = x.reshape((1,) + x.shape + (1,))\n        y = labels_array[index]\n        # appending mismatched images\n        images_mismatched.append(x)\n        labels_mismatched.append(y)\n\n# converting images_mismatched list to numpy array\nimages_mismatched = np.array(images_mismatched)\nlabels_mismatched = np.array(labels_mismatched)\n\nprint(len(images_mismatched))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Run this code cell to produce augmented images and exported to csv file**","metadata":{}},{"cell_type":"code","source":"# file path of directory where augmented images will be stored inthe form of csv file\nfile_path_aug = \"augmented_data_resnet50v2__19th_batch_training.csv\"\n\n# using tf built-in function to produce randomly augmentded image\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=False,\n    vertical_flip=False)\n\naugmented_images = [] # this will be used to store all augmented images\ntotal_augmented_images = 2500 # total augmented images to be created\naugmentation_per_image = int(total_augmented_images/images_mismatched.shape[0]) # number of augmented images to be \n                                                                                # created per image\n# this loop will be used to perform datagen.flow on all images\nfor i in range(0, len(images_mismatched)):\n    batches = 0\n    # in this loop each image will be used to produce augmented images\n    # until the loop breaks\n    for x_batch in datagen.flow(images_mismatched[i], batch_size=1):\n        x_batch = x_batch.reshape((-1)) # reshapes x_batch to (784,)\n        x_batch = np.insert(x_batch, 0, labels_mismatched[i]) # Insert label at the beginning of the array\n        augmented_images.append(x_batch)\n        batches += 1\n        if batches > augmentation_per_image:\n            # we need to break the loop by hand because\n            # the generator loops indefinitely\n            break\n\naugmented_images = np.array(augmented_images) # converting list to numpy array\naugmented_images = augmented_images.astype(int) # converting float datatype to int\n\n# saving augmented images to csv file\nheader = \",\".join([\"label\"] + [f\"pixel{i}\" for i in range(augmented_images.shape[1]-1)])\nnp.savetxt(file_path_aug, augmented_images, delimiter=',', header=header, comments='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Run this code cell to augment entire training data**","metadata":{}},{"cell_type":"code","source":"# file path of directory where augmented images will be stored inthe form of csv file\ntrain_data = \"/kaggle/input/digit-recognizer/train.csv\"\n\n# file path of directory where augmented images will be stored inthe form of csv file\nfile_path_aug = \"augmented_data_all_.csv\"\n\n# using tf built-in function to produce randomly augmentded image\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=False,\n    vertical_flip=False)\n\naugmented_images = [] # this will be used to store all augmented images\n\n# this loop will be used to perform datagen.flow on all images\nfor i in range(0, images.shape[0]):\n    batches = 0\n    # in this loop each image will be used to produce augmented images\n    # until the loop breaks\n    for x_batch in datagen.flow(images[i].reshape(1,28,28,1), batch_size=1):\n        x_batch = x_batch.reshape((-1)) # reshapes x_batch to (784,)\n        x_batch = np.insert(x_batch, 0, labels_array[i]) # Insert label at the beginning of the array\n        augmented_images.append(x_batch)\n        batches += 1\n        if batches > 2:\n            # we need to break the loop by hand because\n            # the generator loops indefinitely\n            break\n\naugmented_images = np.array(augmented_images) # converting list to numpy array\naugmented_images = augmented_images.astype(int) # converting float datatype to int\nprint(augmented_images.shape)\n\n# saving augmented images to csv file\nheader = \",\".join([\"label\"] + [f\"pixel{i}\" for i in range(augmented_images.shape[1]-1)])\nnp.savetxt(file_path_aug, augmented_images, delimiter=',', header=header, comments='')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}